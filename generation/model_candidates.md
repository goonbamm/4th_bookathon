## Model Candidates ğŸ”¥

<br>

||checkpoint|model structure|size|characteristic|License|
|:-:|:-:|:-:|:-:|:-:|:-:|
|1|[skt/kogpt2-base-v2](https://huggingface.co/skt/kogpt2-base-v2)|GPT2|Base (110M)|KoGPT2 ì€ ëŒ€ë¶€ë¶„ ì´ê±¸ finetuning í•¨.|CC BY-NC-SA 4.0 |
|2|[kykim/gpt3-kor-small_based_on_gpt2](https://huggingface.co/kykim/gpt3-kor-small_based_on_gpt2)|GPT2<br>(reflects GPT3 structure)|Base (110M)|KoGPT3 ì˜ êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ê³ , 70GB(ë‚˜ë¬´ìœ„í‚¤, ë¸”ë¡œê·¸ ê¸€ ë“±) ë” ë§ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „í•™ìŠµí•œ ëª¨ë¸|Apache License 2.0|
|3|[ttop324/kogpt2novel](https://huggingface.co/ttop324/kogpt2novel)|GPT2|Base (110M)|1ë²ˆ ëª¨ë¸ì— ì†Œì„¤ë¡œ finetuning í•¨.|-|
|4|[ttop324/kogpt2jnovel](https://huggingface.co/ttop324/kogpt2jnovel)|GPT2|Base (110M)|ì¼ë³¸ ì†Œì„¤ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ì—¬ finetuning í•œ ëª¨ë¸ì´ë¼ê³  í•¨.|-|
|5|[gogamza/kobart-base-v2](https://huggingface.co/gogamza/kobart-base-v2)|BART|Base (130M)|40GB ì´ìƒì˜ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ í•™ìŠµí•œ í•œêµ­ì–´ encoder-decoder ì–¸ì–´ ëª¨ë¸|modified MIT|
|6|[kykim/bertshared-kor-base](https://huggingface.co/kykim/bertshared-kor-base)|encoder-decoder|Base (130M)|seq2seqëª¨ë¸ë¡œ encoderì™€ decoderë¥¼ bert-kor-baseë¡œ ì´ˆê¸°í™”í•œ ë‹¤ìŒ trainingì„ í•œ ê²ƒ. Encoderì™€ decoderê°€ íŒŒë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ê²Œ í•¨ìœ¼ë¡œì¨ í•˜ë‚˜ì˜ bert ëª¨ë¸ ìš©ëŸ‰ìœ¼ë¡œ seq2seqë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŒ.|Apache License 2.0|
|7|[monologg/kobigbird-bert-base](https://huggingface.co/monologg/kobigbird-bert-base)|BigBird|Base (110M)|ìµœëŒ€ 512ê°œì˜ tokenì„ ë‹¤ë£° ìˆ˜ ìˆëŠ” BERTì˜ 8ë°°ì¸ ìµœëŒ€ 4096ê°œì˜ tokenì„ ë‹¤ë£¸.  Full attentionì´ ì•„ë‹Œ Sparse Attentionì„ ì´ìš©í•˜ì—¬ O(n2)ì—ì„œ O(n)ìœ¼ë¡œ ê°œì„ í•¨.|Apache License 2.0|
|8|[paust/pko-t5-base](https://huggingface.co/paust/pko-t5-base)|T5|Base (250M)|í•œêµ­ì–´ ë°ì´í„° (ë‚˜ë¬´ìœ„í‚¤, ìœ„í‚¤í”¼ë””ì•„, ëª¨ë‘ì˜ë§ë­‰ì¹˜ ë“±..) ë¥¼ T5 ì˜ span corruption task ë¥¼ ì‚¬ìš©í•´ì„œ unsupervised learning ë§Œ ì ìš©í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•¨.|MIT license|
